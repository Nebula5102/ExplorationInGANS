# ExplorationInGANS

### Abstract
This paper is an exploration in Generative Adversarial Networks (GANs). Two types of GANs are discussed: GAN, and WGAN. The main goal is to display the strengths and weaknesses of GAN and WGAN, as well as outline the need for tools to recognize artificially generated images, and understand why GANs may not be the best models suited for that task.

### Introduction
Over the span of a year and four months generative models such as Chat-GPT, Claude, Bard, Midjourney, SORA, etc. have made a monumental impact on the world of artificial intelligence. More specifically Open-AI's SORA model, although still not released to the public, has shown evidence that generative models can create extremely realistic and convincing video compositions. These models will continue to get better, more advanced, and less distinguishable from reality. Open-AI, and Midjourney have both claimed that they will begin to watermark their images, and hopefully videos to indicate that their media was generated by artificial intelligence. However, there will be open source models competing with the image quality of models like SORA, and these open source models have no obligation to show any indication of their generated media being fake. In light of this, the tools we use to recognize artificial images from real ones must also be able to compete with these generative models. In this paper I will explore generative adversarial networks (GANs) their strengths and weaknesses, and hopefully outline why this is not a good approach for recognizing artificially generated images. 

Why explore GANs? GANs are compelling because like Midjourney, they are generative. Additionally, they are made up of two neural networks known as the discriminator, and generator. Essentially, the discriminator and generator compete against each other, which is where the adversarial part comes from. In theory, if the generator were able to become as good as Midjourney is at creating images, the discriminator would be equally as good at recognizing those images, which is a solution to the aforementioned problem. 

### Related Work

GANs are not new technology, and they have been generating images since the [Generative Adversarial Nets](https://arxiv.org/abs/1406.2661) paper which is the model I will be adopting by following this python [tutorial](https://realpython.com/generative-adversarial-networks/). There have been a number of new models developed that improve on the reliability of training and image quality [karras2020analyzing](https://arxiv.org/abs/1912.04958) as well as reduce the likelihood of mode collapse [arjovsky2017wasserstein](https://arxiv.org/abs/1701.07875). This paper only explores Wasserstein GAN and GAN.

Unfortunately, this is a field that is changing at a rapid pace. There are little to no papers exploring the idea of recognizing artificially generated images from real ones, however there are teams exploring how to protect artists in the AI space, such as [Glaze](https://arxiv.org/abs/2302.04222). This paper explores a effective technique to protect an artist's work. Their technique involves extracting features from paintings or drawings and subsequently altering the image based on the features they extracted. The altered images make it extremely hard for generative models to copy the style of the art piece, protecting that artists work. 

### Training Devices

To get this model training, google Colab was the first source of compute. Unfortunately, there is a time cap on how long function can be running idle on the Colab GPUs. This caused numerous problems. When the timeout occurs the kernal restarts causing not only the training loop to be halted, but additionally the storage used is dumped. After ten hours of training the first GAN the Colab servers timed out the process and all the data was lost. Since GANs take a lot of compute, and a long time to train there were only two solutions. Write a script to make sure colab does not time out or run the program on a local device. I opted for the latter option. The local device used to train the GAN models contained a NVIDIA GeForce RTX 2070 Super with 8 Gb of GDDR6. After switching from Colab to the local device the speed of training was much faster, and the model could train indefinitely. 

### Training Data
The original training set used for the GAN model was a [landscape dataset](https://www.kaggle.com/datasets/utkarshsaxenadn/landscape-recognition-image-dataset-12k-images), however, the dataset proved to be too broad for both the GAN and WGAN to produce any meaningful images. To attempt to produce more refined images a subset of this dataset was used, specifically the mountain images. This produced interesting results after 10 000 epochs, but still nothing close to a truly recognizable image of a mountain. It was clear a simpler type of image needed to be used. The dataset chosen was the following fish [dataset](https://www.kaggle.com/datasets/markdaniellampa/fish-dataset). After 5 000 epochs the fish GAN was not performing better than the mountain GAN, so it was time to move to something even simpler. That simpler dataset was the google cartoon faces [dataset](https://www.kaggle.com/datasets/brendanartley/cartoon-faces-googles-cartoon-set). 5 000 epochs of training through the WGAN model allowed the generator to produce images with features similar to the faces of the dataset. Although they were not identical, there was a considerable improvement in results compared to the original dataset.

### Conclusion

As seen in the results the generator did not produce images that were anywhere close to that of the Midjourney, or Open-Ai's models. This means, subsequently the discriminator would also perform poorly in recognizing artificially generated images by Midjourney, chat-GPT, or SORA. The reality of GANs is that they are too fragile to compete against other generative models. To properly train a model the training set must contain a large amount of clean photo data of the same or similar image types. Additionally, the time taken to train the models is equally as large. These facts coupled with the possibility of mode collapse from the generator makes the training of GANs for the purpose of artificial intelligence image recognition infeasible.
